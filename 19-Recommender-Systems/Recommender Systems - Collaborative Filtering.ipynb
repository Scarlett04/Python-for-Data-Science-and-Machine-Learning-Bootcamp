{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddefbb5c",
   "metadata": {},
   "source": [
    "# Recommendation System with Python\n",
    "Welcome!  \n",
    "This project builds movie recommendations using Python to show how recommender systems work in practice. Usually, there are 2 common approaches to build a recommendation system:\n",
    "\n",
    "- **Content-based filtering (CBF):** Focus on the attributes of the items (genre, keywords, descriptions, etc.).\n",
    "  *Example:* If you liked a sci-fi action film, it suggests other sci-fi action films.\n",
    "- **Collaborative Filtering (CF):** Focus on users' attitude to items (based on rating / interaction history).\n",
    "  *Example:* If users who liked the same movies as you also liked a certain film, that film is recommended.\n",
    "\n",
    "## Data\n",
    "We use the **MovieLens 100K** dataset, which contains 100,000 movie ratings from 943 users on 1,682 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04527c89",
   "metadata": {},
   "source": [
    "## Methods\n",
    "In this notebook, we implement **collaborative filtering** (CF), which learns from patterns of user ratings. Collaborative filtering assumes that users with similar past behavior will rate items similarly. \n",
    "\n",
    "Unlike content-based filtering, CF does not require item metadata. Instead, we will use:\n",
    "- <u>Memory-based:</u> use similarity between users or between items (e.g., cosine similarity on the rating matrix).\n",
    "    + *User-User CF*: \"Users who rate movies like you also liked …\"\n",
    "    + *Item-Item CF*: \"Users who liked this movie also liked …\"\n",
    "- <u>Model-based:</u> use machine learning models to learn hidden patterns from the matrix (e.g., **Singular Value Decomposition (SVD)**).\n",
    "\n",
    "**Why this method:**  \n",
    "- Capture hidden relationships (latent factors) between users and items.  \n",
    "- Can produce richer, more personalized recommendations when enough data is available.\n",
    "\n",
    "We will:\n",
    "1. Implement a memory-based CF using cosine similarity on the user-item rating matrix.\n",
    "2. Implement a model-based CF using **SVD** to uncover latent factors for users and movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06246058",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d62435ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fac4201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       50       5  881250949\n",
       "1        0      172       5  881250949\n",
       "2        0      133       1  881250949\n",
       "3      196      242       3  881250949\n",
       "4      186      302       3  891717742"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# Since the data is tab separated, we use sep='\\t' to tell pandas read_csv method that the data is tab separated.\n",
    "df = pd.read_csv('u.data', sep='\\t', names=columns_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39897c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title\n",
       "0        1   Toy Story (1995)\n",
       "1        2   GoldenEye (1995)\n",
       "2        3  Four Rooms (1995)\n",
       "3        4  Get Shorty (1995)\n",
       "4        5     Copycat (1995)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv('Movie_Id_Titles')\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf6ffca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Gone with the Wind (1939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp                            title\n",
       "0        0       50       5  881250949                 Star Wars (1977)\n",
       "1        0      172       5  881250949  Empire Strikes Back, The (1980)\n",
       "2        0      133       1  881250949        Gone with the Wind (1939)\n",
       "3      196      242       3  881250949                     Kolya (1996)\n",
       "4      186      302       3  891717742         L.A. Confidential (1997)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge them together\n",
    "df = pd.merge(df, movie_titles, on='item_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d6c3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Users: 944\n",
      "Num of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_items = df.item_id.nunique()\n",
    "\n",
    "print('Num. of Users: '+ str(n_users))\n",
    "print('Num of Movies: '+str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dd0b0",
   "metadata": {},
   "source": [
    "Train-Test-Split: segment the data into 2 sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9456ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b3fce",
   "metadata": {},
   "source": [
    "## Memory-Based Collaborative Filtering\n",
    "\n",
    "### Concept Overview\n",
    "Memory-based collaborative filtering predicts a user's preference for an item by directly comparing ratings in the existing user-item matrix. Instead of learning model parameters, it uses **similarity measures** to find relationships:\n",
    "\n",
    "* **User-User CF**: Recommend items that similar users have liked.  \n",
    "* **Item-Item CF**: Recommend items similar to the ones a user has liked.\n",
    "\n",
    "### How does it work\n",
    "1. Represent the rating matrix (R) where (R_{u,i}) is the rating of user (u) on item (i).  \n",
    "2. Similarity between two users (u) and \\(v) (or two items (i) and (j)) is measured by **cosine similarity**:\n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "3. Predict the rating for user (u) on item (i):\n",
    "- **User-User CF**: Predict a user's rating by taking user's average rating plus a weighted correction based on how similar users rated the item differently from their own averages.\n",
    "\n",
    "![alt text](image-1.png)\n",
    "\n",
    "- **Item-Item CF**: Predict a user's rating by taking the weighted average of the user's ratings on items that are similar to the target item.\n",
    "\n",
    "![alt text](image-2.png)\n",
    "\n",
    "_Note: ( bar{r}\\_u ) is the average rating of user (u). ( s\\_{u,v} ) and ( s\\_{i,j} ) are similarity scores_\n",
    "\n",
    "### Advantages\n",
    "- Simple and intuitive - \"people with similar tastes like similar things.\"\n",
    "- No need for item metadata (genres, keywords, etc.).\n",
    "- Good baseline to understand how collaborative filtering works.\n",
    "\n",
    "### Limitations\n",
    "- **Scalability**: Similarity calculations grow as data grows.\n",
    "- **Cold-start**: Can not recommend for new users or new items with no ratings.\n",
    "- Sensitive to data sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648624df",
   "metadata": {},
   "source": [
    "**Build User-Item Matrices**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "165e510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two user-item matrices, one for training and another for testing. Each cell is the rating a user gave a movie\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]  \n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62aeaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df915e1",
   "metadata": {},
   "source": [
    "**Compute Similarity** (using pairwise distance function to calculate cosine similarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6620da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between users and items\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9651cddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.8503478 , 0.97281132, ..., 0.88147318, 0.67600427,\n",
       "        1.        ],\n",
       "       [0.8503478 , 0.        , 0.97979365, ..., 0.86585467, 0.95211479,\n",
       "        1.        ],\n",
       "       [0.97281132, 0.97979365, 0.        , ..., 0.93426275, 0.97749468,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.88147318, 0.86585467, 0.93426275, ..., 0.        , 0.91193451,\n",
       "        1.        ],\n",
       "       [0.67600427, 0.95211479, 0.97749468, ..., 0.91193451, 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2141773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.70804127, 0.77852594, ..., 1.        , 1.        ,\n",
       "        0.94420716],\n",
       "       [0.70804127, 0.        , 0.87835353, ..., 1.        , 0.91003598,\n",
       "        1.        ],\n",
       "       [0.77852594, 0.87835353, 0.        , ..., 1.        , 1.        ,\n",
       "        0.88409989],\n",
       "       ...,\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.91003598, 1.        , ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.94420716, 1.        , 0.88409989, ..., 1.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81522bc",
   "metadata": {},
   "source": [
    "**Predict Ratings**:\n",
    "- User-based CF: Adjust predictions by each user's mean rating (to account for users who rate higher or lower on average).\n",
    "- Item-based CF: Use item similarity, no need for mean adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c01c94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        # Use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])     \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5872b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fe79a",
   "metadata": {},
   "source": [
    "**Evaluation**: Here, we can evaluate our model by using Root Mean Squared Error (RMSE) to quantify how close predictions are to actual ratings.\n",
    "Lower RMSE = better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() # Only consider predicted ratings that are actually rated by users\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "956405f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 3.1127818146863335\n",
      "Item-based CF RMSE: 3.4420188636509703\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c783f",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Accuracy:\n",
    "- User-based CF RMSE ≈ 3.11\n",
    "- Item-based CF RMSE ≈ 3.44\n",
    "\n",
    "=> User-based CF performed slightly better, suggesting user-to-user similarities captured stronger patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cc7a7",
   "metadata": {},
   "source": [
    "## Model-Based Collaborative Filtering\n",
    "\n",
    "### Concept Overview\n",
    "Model-based collaborative filtering predicts ratings by **learning hidden factors** that explain user preferences and item characteristics, instead of relying solely on direct similarity between rating patterns. The most common model-based approach is **Matrix Factorization (MF)**, where we decompose the large, sparse user-item rating matrix into the product of lower-dimensional matrices that represent **latent features** (hidden patterns). \n",
    "\n",
    "<u>Key idea</u>: Even if two users have not rated the same movies, they might share hidden preferences (e.g., \"likes 80s sci-fi\" or \"prefers romantic comedies\"). Matrix factorization uncovers these hidden dimensions and uses them to predict unknown ratings.\n",
    "\n",
    "### How does it work\n",
    "In this project, we will use a well-known matrix factorization method called **Singular value decomposition (SVD)**.\n",
    "\n",
    "Given a user-item matrix ( R ) of size ( m x n ), matrix factorization approximates ( R ) as:\n",
    "\n",
    "![alt text](image-3.png)\n",
    "\n",
    "where:\n",
    "- ( R ): the original matrix (e.g., user-item ratings).\n",
    "- ( U ): a ( m x k ) orthogonal matrix representing user feature vectors (\"latent factors\").\n",
    "- ( S ): a ( k x k ) diagonal matrix of singular values (strength of each factor).\n",
    "- ( V^T ): a ( k x n ) transpose of matrix representing item feature vectors.\n",
    "\n",
    "### Advantages\n",
    "- Handles **sparsity** better than memory-based CF.\n",
    "- Scales to large datasets.\n",
    "- Captures deeper, abstract relationships (latent factors) beyond simple rating overlap.\n",
    "\n",
    "### Limitations\n",
    "- Need enough rating data to learn meaningful factors.\n",
    "- Susceptible to cold-start problems (new users or new items with no ratings).\n",
    "- SVD can be computationally expensive and may overfit if not regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a54b1",
   "metadata": {},
   "source": [
    "First, let's check the sparsity of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens100K is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(df)/float(n_users*n_items),3)\n",
    "print('The sparsity level of MovieLens100K is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2258370",
   "metadata": {},
   "source": [
    "Here, the dataset is **~94%** sparse, which indicates that most user-movie pairs are unrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7d3ea",
   "metadata": {},
   "source": [
    "Apply **Singular Value Decomposition (SVD)**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db784a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Factorize the training matrix into three low-rank matrices. Choose appropriate k (number of latent factors)\n",
    "# Set k=20 keeps only the top 20 latent factors, which capture the most significant patterns and reduce noise. \n",
    "u, s, vt = svds(train_data_matrix, k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "600d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the three SVD components to reconstruct an approximation of the original rating matrix, which contains the predicted ratings for every user-movie pair\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8585a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 2.7107675909887847\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with RMSE\n",
    "print('User-based CF MSE: ' + str(rmse(X_pred, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeed8cf",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Accuracy:\n",
    "- Model-based CF with SVD RMSE ≈ 2.71\n",
    "\n",
    "=> Overall, the model-based CF with SVD achieved a lower RMSE (~2.71) than the memory-based methods (~3.13 user-based, ~3.46 item-based), indicating that this approach performs better and effectively captures hidden factors (such as decade, genre, or actor preferences) and predicts ratings more accurately, even when many user-movie pairs are missing.\n",
    "\n",
    "<u>Extra Note</u>: We can also use Hybrid Recommender System, which combines Collaborative Filtering and Content-based models. This approach can further increase accuracy and address cold-start issues (use metadata from the user/item to make a prediction if no ratings available)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
